---
layout: post
title: Maximize a Posterior
tags: [MLDL]
permalink: /2023-spring/mldl/map
---

# MAP

# Binomial Distribution

## Bayesian Learning

Recall Bayes rule,

$$
P(p\|\mathcal{D}) = \frac{P(\mathcal{D}\|p)P(p)}{P(\mathcal{D})}
$$

In MAP, $$P(p\|\mathcal{D})\propto P(\mathcal{D}\|p)P(p)$$. Thus, the prior $$P(p)$$ is important. There is a special prior called **conjugate prior**(cp). If a prior is in the same probability distribution family with the posterior $$P(p\|\mathcal{D})$$, we say it is a conjugate prior to the likelihood function. In this case, it is easier to compute. For example, for binomial likelihood function, beta distribution is the conjugate prior (beta prior).

## Beta Distribution

A **beta distribution** $$P(p)$$ is expressed as

$$
P(p)=\frac{p^{\beta_H-1}(1-p)^{\beta_T-1}}{B(\beta_H, \beta_T)} \sim Beta(\beta_H, \beta_T)
$$

where $$B(\beta_H, \beta_T)$$ is a constant.

It is similar with binomial distribution $$p^x(1-p)^{n-x}$$. The probability $$p$$ is fixed and each trial varies in the binomial distribution, but in beta distribution, $$p$$ varies while the trials $$(\beta_H-1$$ and $$\beta_T-1)$$ are fixed.

Also, its mode can be computed by

$$
mode: \frac{\beta_H-1}{\beta_H+\beta_T-2}
$$

This fact makes us easier to complete our MAP process!

Now, we will show how beta prior makes posterior simple.

We have binomial likelihood function of

$$
P(\mathcal{D}\|p) = \binom{\alpha_H+\alpha_T}{\alpha_T}p^{\alpha_H}(1-p)^{\alpha_T}
$$

and beta prior of

$$
P(p)= \frac{p^{\beta_H-1}(1-p)^{\beta_T-1}}{B(\beta_H, \beta_T)}
$$

Since posterior is proportional to the product of them,

$$
\begin{align*}
P(p\|\mathcal{D}) &\propto P(\mathcal{D}\|p)P(p)\\
&= p^{\alpha_H}(1-p)^{\alpha_T}p^{\beta_H-1}p^{\beta_T-1}\\
&= p^{\alpha_H+\beta_H-1}(1-p)^{\alpha_T+\beta_T-1}\\
&\propto Beta(\alpha_H+\beta_H, \alpha_T+\beta_T)
\end{align*}
$$

Therefore, the posterior is given by beta distribution.

Moreover, beta distribution is very useful for MAP. We know that mode of beta distribution $$Beta(\beta_H, \beta_T)$$ is $$\frac{\beta_H-1}{\beta_H+\beta_T-2}$$. With this fact, we can solve MAP problem,

$$
\hat{p}=\arg \max_iP(p\|\mathcal{D})=\frac{\alpha_H+\beta_H-1}{\alpha_H+\beta_H+\alpha_T+\beta_T-2}
$$

By definition, mode is a value that is most likely to happen.

From our derivation, we can summarize that

- Beta prior is equivalent to extra toss (added observation)
- As $$N \rightarrow \infty$$, the prior is unimportant → observation > prior
- As $$N \rightarrow 0$$, the prior is important

## MLE vs. MAP

**MLE** choose $$\theta$$ that maximizes likelihood $$P(\mathcal{D}\|\theta)$$

$$
\hat{\theta}^{MLE}=\frac{\alpha_H}{\alpha_H+\alpha_T}
$$

**MAP** choose $$\theta$$ that maximizes posterior $$P(\theta\|\mathcal{D})$$

$$
\hat{\theta}^{MAP}= \frac{\alpha_H+\beta_H-1}{\alpha_H+\beta_H+\alpha_T+\beta_T-2}
$$

# Gaussian Distribution

In the previous section, we have discussed MLE and MAP for the coin toss, a random variable following binomial distribution. In this case, the variable is discrete.

For the continuous variable, we will use **Gaussian distribution**.

$$
\mathcal{N}(x; \mu,\sigma^2)=\frac{1}{\sqrt{2\pi\sigma^2}}\exp\big\{-\frac{1}{2\sigma^2}(x-\mu)^2\big\}
$$

Gaussian distribution is often used in machine learning due to some properties, involving central limit theorem. It can be computed conviniently using $$\log$$ to convert multiplication to addition. Also mixture of Gaussian can approximate numerous distributions and closely related to squared losses.

### Moments and Multivariate Gaussian

For a Gaussian distribution $$\mathcal{N}(x;\mu, \sigma^2)$$, expectation and variance are given by

$$
E[x]=\int_{-\infty}^\infty x\mathcal{N}(x; \mu, \sigma^2) = \mu\\
\text{var}\; x = \int_{-\infty}^{\infty}(x-\mu)^2\mathcal{N}(x; \mu, \sigma^2)=\sigma^2
$$

Also, variable of Gaussian distribution can be a vector $$\mathbf{x}$$ in $$\mathbb{R}^d$$

$$
\mathcal{N}(\mathbf{x}; \mathbf{\vec \mu},\mathbf{\Sigma})= \frac{1}{(2\pi)^{d/2}\|\mathbf{\Sigma}\|^{1/2}}\exp(-\frac{1}{2}\big(\mathbf{x}-\vec\mu)^T\mathbf{\Sigma}^{-1}(\mathbf{x}-\vec\mu)\big)
$$

Similarly, the expectation and covariance of $$\mathbf{x}$$ are given by

$$
E[\mathbf{x}]=\vec\mu\\
E[(\mathbf{x}- \vec\mu)(\mathbf{x}- \vec\mu)^T] = E[\mathbf{x}\mathbf{x}^T]-\vec\mu\vec\mu^T=\mathbf{\Sigma}
$$

## Properties

Gaussian has useful properties. First, Affine transformations are also Gaussian. That is, for $$X\sim N(\mu, \sigma^2)$$,

$$
Y=aX+b\rightarrow Y\sim N(a\mu+b, a^2\sigma^2)
$$

Also, sum of Gaussian is Gaussian distribution.

$$
X\sim N(\mu_x, \sigma_x^2)\\
Y\sim N(\mu_y, \sigma_y^2)\\
Z=X+Y \rightarrow Z\sim N(\mu_x+\mu_y, \sigma_x^2+\sigma_y^2)
$$

# Learning Gaussian

Now, as we did before, we will estimate the parameters of the Gaussian. For Gaussian, we have two learning parameters, namely, $$\mu$$ and $$\sigma^2$$. Both MLE and MAP is possible, but we will spend most of time on MLE.

## MLE for Univariate Gaussian

Suppose you have independent and identically distributed (i.i.d.)

$$
x_1, x_2, \dots, x_R \sim N(\mu, \sigma^2),
$$

and you know $$\sigma^2$$ but don’t know $$\mu$$. We will use MLE to find $$\mu$$ such that $$x_1, x_2, \dots , x_R$$ most likely be. Formally, we will find $$\mu$$ such that

$$
\mu^{MLE} = \arg\max_\mu p(x_1, x_2, \dots, x_R\|\mu, \sigma^2)
$$

We will follow five steps for finding MLE $$\theta$$ assuming known form for $$p(\mathcal{P}\|\theta)$$:

1. Write $$\log$$-likelihood $$LL=\log p(\mathcal{D}\|\theta)$$
2. Compute $$\frac{\partial LL}{\partial \theta}$$ using calculus
3. Set $$\frac{\partial LL}{\partial \theta} = 0$$ for a maximum, in terms of $$\theta$$
4. Solve it and find $$\hat\theta$$
5. Check if $$\theta$$ is a maximum rather than minimum or saddle point, and $$\theta$$ is out of bound.

Then, lets start computation!

$$
\begin{align*}
\mu^{MLE} &= \arg\max_\mu p(x_1, x_2, \dots, x_R\| \mu, \sigma^2)\\
& = \arg\max_\mu \prod_{i=1}^{R}p(x_i\| \mu,\sigma^2 )&(\text{i.i.d.})\\
&= \arg \max_\mu \log \sum_{i=1}^{R}p(x_i\|\mu, \sigma^2) &(\text{monotonicity})\\
&= \arg\max_\mu (\log(\frac{R}{\sqrt{2\pi\sigma^2}}+ \sum_{i=1}^{R}-\frac{(x_i-\mu)^2}{2\sigma^2}) &(\text{Gaussian})\\
&= \arg\min_\mu\sum_{i=1}^{R}(x_i-\mu)^2
\end{align*}
$$

Note that $$\arg \max$$ has been converted to $$\arg\min$$ due to its sign. Now we need to compute $$\partial LL/ \partial \mu$$ to find $$\mu^{MLE}$$.

$$
\begin{align*}
0 = \frac{\partial LL}{\partial \mu} &= \frac{\partial}{\partial \mu} \sum_{i=1}^R (x_i-\mu)^2\\
&= -\sum_{i=1}^r (x_i-\mu)^2 \\
&\therefore\mu^{MLE} = \frac{1}{R}\sum_{i=1}^R x_i
\end{align*}
$$

The result says that “the best estimate of the mean of the distribution is the mean of the sample”

### More General Case

In the previous section, we only had one parameter, that is, $$\theta = \mu$$. But what if we don’t know both of $$\mu$$ and $$\sigma^2$$. Then, we need to set $$\vec\theta=(\mu, \sigma^2)$$.

Generally, we can find MLE $$\vec \theta$$ by doing similarly,

$$
\frac{\partial LL}{\partial \theta_1} = 0\\
\frac{\partial LL}{\partial \theta_2} = 0\\
\vdots\\
\frac{\partial LL}{\partial \theta_n} = 0
$$

For our problem, we need to solve

$$
\frac{\partial LL}{\partial \mu} =  0 \;\;\ \text{and} \;\; \frac{\partial LL}{\partial \sigma^2} = 0
$$

We have,

![Untitled](MAP%20d28a819b5609445cad7ffbc3bcca2bac/Untitled.png)

By solving those equations, we find the best estimate for $$\mu$$ and $$\sigma ^2$$ as

$$
\mu^{mle}=\frac{1}{R}\sum_{i=1}^{R}x_i\\
\sigma^2_{mle}=\frac{1}{R}\sum_{i=1}^R (x_i-\mu^{mle})^2
$$

### Biased and Unbiased Parameters

An estimator of a parameter is **unbiased** if the expected value of the estimate is the same as the true value of the parameters.

For example, $$\mu^{mle}$$ is unbiased since for $$x_1, x_2, \dots x_R \sim N(\mu, \sigma^2)$$,

$$
E[\mu^{mle}]=E[\frac{1}{R}\sum_{i=1}^Rx_i]=\mu
$$

However, $$\sigma^2$$ is biased because

$$
E[\sigma^2_{mle}]=E[\frac{1}{R}\sum_{i=1}^{R}(x_i-\mu^{mle})^2 = (1-\frac{1}{R})\sigma^2 \neq \sigma^2
$$

- Specific Proof
  ![Untitled](MAP%20d28a819b5609445cad7ffbc3bcca2bac/Untitled.jpeg)
  ![Untitled](MAP%20d28a819b5609445cad7ffbc3bcca2bac/Untitled%201.jpeg)

Intuitively, for the case of $$R= 1$$ , it seems that our estimation is very bad. Although it won’t matter if the sample has large size, but $$\sigma^2_{mle}$$ will always be the underestimate of true $$\sigma^2$$. Now we need to modify our $$\sigma^2$$ unbiased.

Let us define

$$
\sigma_{unbiased}^2 = \frac{\sigma_{mle}^2}{1-1/R}
$$

Then, according to our previous derivation, we have $$E[\sigma_{unbiased}^2]=\sigma^2$$ and

$$
\sigma_{unbiased}^2 =\frac{1}{R-1}\sum_{i=1}^R (x_i - \mu^{mle})^2
$$

## MAP for Univariate Gaussian

Now, assume you have a Gaussian prior of $$p(u) \sim N(\nu, \beta^2)$$ and don’t know $$\mu$$. A MAP problem for univariate Gaussian is that of which $$\theta = (\mu, \theta^2)$$ maximizes the posterior $$p(\mu\|x_1,\dots x_R, \sigma^2)$$.

First, we need to compute the likelihood function. (Note that number of variables is $$N$$, not $$R$$)

$$
P(x_1, x_2,\dots, x_N) =\prod_{i=1}^{N}P(x_i\|\mu) = \prod_{i=1}^N\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x_i-\mu)^2}{2\sigma^2}}
$$

Second, compute the priors

$$
P(\mu)=\frac{1}{\sqrt{2\pi\beta^2}}e^{-\frac{(\mu-\nu)^2}{2\beta^2}}
$$

Then, compute the posterior

$$
P(\mu\|x_1, \dots, x_N) = P(x_1, \dots, x_N\|\mu)\times P(\mu)
$$

![Untitled](MAP%20d28a819b5609445cad7ffbc3bcca2bac/Untitled%201.png)

By solving $$\partial LL/\partial\mu = 0$$ and $$\partial LL /\partial\sigma^2 = 0$$, and using **cp** (Gaussian) we have

$$
P(\mu\|x_1, x_2, \dots x_N) = N(\hat\mu, \hat\sigma^2),\;\; \text{where}
$$

$$
\hat\mu = \frac{\sigma^2}{N\beta^2+\sigma^2}\nu + \frac{N\beta^2}{N\beta^2+\sigma^2}\mu^{MLE}\\
\hat\sigma^2 = \frac{\beta^2\sigma^2}{N\beta^2+\sigma^2}
$$

Recall that for $$X\sim N(\mu_x, \sigma_x^2)$$ and $$Y\sim N(\mu_y, \sigma_y^2)$$,
$$Z=X+Y\sim N(\mu_x+\mu_y, \sigma_x^2 + \sigma_y^2$$ to use conjugate prior.

$$\hat\mu$$ has two components, $$\frac{\sigma^2}{N\beta^2+\sigma^2}\nu$$ and $$\frac{N\beta^2}{N\beta^2+\sigma^2}\mu^{MLE}$$. It can be intuitively understood that as

- $$N\rightarrow \infty$$ , then $$\hat\mu=\mu^{MLE}$$ : many observations ignore prior
- $$N\rightarrow 0$$, then $$\hat\mu = \nu$$ : prior ignores few observations
- $$\beta\rightarrow 0$$, then $$\hat\mu = \nu$$ : does not change much if variance is small
